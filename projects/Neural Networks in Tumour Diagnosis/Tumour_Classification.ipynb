{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MattFleisch/AI_1/blob/main/AI2_Tumour_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Brain Tumour Classification**\n",
        "---\n",
        "### Ariel Levy (LVYARI002)\n",
        "### Matthew Flesichman (FLSMAT002)\n",
        "---\n",
        "##### This convolutional neural network (CNN) makes use of a [dataset](https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri) of 3264 labelled brain scan images to predict the presence and type of tumours. There are four possible classes: *meningioma tumour*, *glioma tumour*, *pituitary tumour*, and *no tumour*. The model achieves an ~90% testing accuracy, signifcantly higher than that of random chance (25%).\n",
        "---"
      ],
      "metadata": {
        "id": "aszSJaxgra1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries\n",
        "These are the libraries that need to be imported in order to construct and display the results of the model.\n"
      ],
      "metadata": {
        "id": "HnZAK0i3rxUu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "599dZcTDSSsu"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import optimizers\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Extraction\n",
        "Here the .zip file is extracted to a folder and its subdirectories are determined. If you download the dataset make sure the file is named `tumor.zip`."
      ],
      "metadata": {
        "id": "NEE7U4sjuwOM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL6BSohtS-4z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "b951bfaf-8b4e-4f1c-89a0-7d5d6609642a"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "filename = \"tumor\"\n",
        "\n",
        "with ZipFile(f'{filename}.zip', 'r') as zipObj:\n",
        "   zipObj.extractall(f'{filename}')\n",
        "\n",
        "import glob\n",
        "f1 = glob.glob(f'/content/{filename}/*')\n",
        "f1 = [f for f in f1 if '__MACOSX' not in f]\n",
        "print(f1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'tumor.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3700627353.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"tumor\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{filename}.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzipObj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m    \u001b[0mzipObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{filename}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tumor.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n",
        "Here the image files (along with their labels) are moved from folders into arrays; training and testing data is combined so that the split can be easily changed later. Image files are converted to greyscale and 64x64, making analysis easier and more resource efficient."
      ],
      "metadata": {
        "id": "mg4HfdzfvChC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAQJDJzvblUK",
        "collapsed": true
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "image_size = 64\n",
        "\n",
        "for dataset_path in f1:\n",
        "    # Get the class names from the subdirectories within 'Training' and 'Testing'\n",
        "    class_names = [name for name in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, name))]\n",
        "\n",
        "    for class_index, class_name in enumerate(class_names):\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        if os.path.exists(class_path):\n",
        "            for image_name in os.listdir(class_path):\n",
        "                image_path = os.path.join(class_path, image_name)\n",
        "                image = cv2.imread(image_path)\n",
        "                # convert image to greyscale and 64x64\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "                image = cv2.resize(image, (image_size, image_size))\n",
        "                images.append(image)\n",
        "                labels.append(class_index)\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity Check\n",
        "Quick check on the shapes of the image and label arrays, as well as the classes involved, to ensure that our data extraction and preparation was successful."
      ],
      "metadata": {
        "id": "xbiT2gvIvoFS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OqDW6y9fhIF"
      },
      "source": [
        "print((images.shape), (labels.shape))\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Showcase\n",
        "A look at a subset of the data being used in this analysis (along with their class labels)."
      ],
      "metadata": {
        "id": "M9jNvgvjv0ht"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19qT9ItNgwjJ"
      },
      "source": [
        "num_images_to_display = 3\n",
        "\n",
        "for _ in range(num_images_to_display):\n",
        "  index = np.random.randint(0, len(images) - 1)\n",
        "  image = images[index]\n",
        "  label = labels[index]\n",
        "  class_name = class_names[label]\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(image, cmap='gray')\n",
        "  plt.title(f\"Class: {class_name}\")\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting Train and Test Data\n",
        "The training and test datasets are split and their shapes displayed. A set seed is used for reproducibility purposes."
      ],
      "metadata": {
        "id": "85fHqKV4wjDb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLkuX2I9jIUg"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.15, random_state=42)\n",
        "\n",
        "print(f\"Train: {x_train.shape}\")\n",
        "print(f\"Test: {x_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalisation\n",
        "Only a single colour channel is used (greyscale), so its value just needs to be scaled from 0 - 255 to 0 - 1."
      ],
      "metadata": {
        "id": "OUZmQRN2w3ZT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj2Im5jmn5fT"
      },
      "source": [
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model\n",
        "A simple CNN structure is used to gauge the effectiveness of more complex models."
      ],
      "metadata": {
        "id": "iLOoip_PURW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constructing Model\n",
        "baseline_model = Sequential()\n",
        "\n",
        "baseline_model.add(Input(shape=(64, 64, 1)))\n",
        "baseline_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "baseline_model.add(MaxPooling2D((2, 2)))\n",
        "baseline_model.add(Flatten())\n",
        "baseline_model.add(Dense(64, activation='relu'))\n",
        "baseline_model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# Training\n",
        "opt = optimizers.Adam(learning_rate = 0.001)\n",
        "baseline_model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = (['accuracy']))\n",
        "hist = baseline_model.fit(x_train, y_train, epochs = 30, batch_size = 32, validation_split = 0.2)\n",
        "\n",
        "# Calculating Accuracies\n",
        "y_train_pred = baseline_model.predict(x_train)\n",
        "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
        "\n",
        "y_pred = baseline_model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred_classes)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Testing Accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "ATB17iyBUj2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Final CNN\n",
        "The CNN model is created using the following architecture:\n",
        "- An **input** layer of size 64x64x1 (i.e. the image resolution).\n",
        "- 3x **convolutional/maxpooling** layers using *relu* activation.\n",
        "- A **flatten** layer used to transition to dense layers.\n",
        "- A single **dense** layer.\n",
        "- An **output** layer which produces a result via *softmax* activation.\n",
        "- Scattered **dropout** layers throughout the model to prevent overfitting.\n"
      ],
      "metadata": {
        "id": "k8xQyYBUxWZS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-GFr7JToXFd"
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input(shape=(64, 64, 1)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.35))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Compilation and Training\n",
        "The model is optimised using the widely-used Adam optimiser - which depends only the learning rate. This is a multi-class classification problem so categorical crossentropy is used as the loss function. Performance is measured using the accuracy metric. Training is done using min-batches over a number of epochs."
      ],
      "metadata": {
        "id": "xXEDscM1y4j3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz-GDDtPpKYh"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state=42)\n",
        "\n",
        "opt = optimizers.Adam(learning_rate = 0.001)\n",
        "model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics = (['accuracy']))\n",
        "hist = model.fit(x_train, y_train, epochs = 30, batch_size = 64, validation_data = (x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Predictions\n",
        "Here one instance of a model's predictive capabilities are shown for a randomly selected test data image. The image's predicted and actual classes are both shown."
      ],
      "metadata": {
        "id": "iTKGwstj0p9g"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRy4bMU5gPeL"
      },
      "source": [
        "y_hat = model.predict(x_test)\n",
        "\n",
        "x = np.random.randint(0, len(x_test))\n",
        "pred_class = np.argmax(y_hat[x])\n",
        "pred_class = class_names[pred_class]\n",
        "acu = class_names[y_test[x]]\n",
        "\n",
        "\n",
        "t = f'Pred -> {pred_class}'\n",
        "p = f'Actual -> {acu}'\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(x_test[x], cmap=\"gray\")\n",
        "plt.title(t)\n",
        "plt.xlabel(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Performance\n",
        "Plotting training and validation accuracies and losses as a function of epoch number to show that the model doesn't overfit."
      ],
      "metadata": {
        "id": "aQLlY23SPr_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy\n",
        "train_acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_acc, 'b.-', label='Training')\n",
        "plt.plot(epochs, val_acc, 'r.-', label='Validation')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# loss\n",
        "train_loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_loss, 'b.-', label='Training')\n",
        "plt.plot(epochs, val_loss, 'r.-', label='Validation')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vjP-TqzQPqnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the training and testing accuracies and F1 scores for the CNN model are calculated and displayed."
      ],
      "metadata": {
        "id": "iQC8e1q71R3A"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwTrjyK30SWi"
      },
      "source": [
        "y_train_pred = model.predict(x_train)\n",
        "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
        "\n",
        "y_val_pred = model.predict(x_val)\n",
        "y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Accuracies\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred_classes)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred_classes)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "\n",
        "# F1 Scores\n",
        "train_f1 = f1_score(y_train, y_train_pred_classes, average='weighted')\n",
        "val_f1 = f1_score(y_val, y_val_pred_classes, average='weighted')\n",
        "test_f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "\n",
        "# Outputting results\n",
        "print(\"Training\")\n",
        "print(f\"\\tAccuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"\\tF1 Score: {train_f1:.3f}\")\n",
        "\n",
        "print(\"\\nValidation\")\n",
        "print(f\"\\tAccuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"\\tF1 Score: {val_f1:.3f}\")\n",
        "\n",
        "print(\"\\nTesting\")\n",
        "print(f\"\\tAccuracy: {test_accuracy*100:.2f}%\")\n",
        "print(f\"\\tF1 Score: {test_f1:.3f}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}